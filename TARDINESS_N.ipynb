{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed2045/Tardiness-Prediction-Model/blob/main/TARDINESS_N.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgSAbFpLZsUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0608af1-a248-4c79-bd80-f1e69109ba5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (6999, 11) (6999,)\n",
            "Validation set shape: (1500, 11) (1500,)\n",
            "Test set shape: (1500, 11) (1500,)\n",
            "Training Accuracy: 98.87126732390341 %\n",
            "Validation Accuracy: 99.2 %\n",
            "Test Accuracy: 98.73333333333333 %\n",
            " Precision is : 0.9875634161886553\n",
            " Recall is : 0.9873333333333333\n",
            " F1 Score is : 0.9872615718299335\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC  # Import Support Vector Classifier\n",
        "\n",
        "# Read the dataset from a CSV file into a pandas DataFrame\n",
        "data = pd.read_csv('dataSET-1.csv')\n",
        "\n",
        "# Define the features and target variable\n",
        "features = ['weather', 'transportation', 'start', 'traffic', 'duration', 'previous tardiness']\n",
        "target = 'tardiness'\n",
        "\n",
        "# Extract features (X) and target variable (y) from the dataset\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Initialize a OneHotEncoder to handle categorical variables\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# Perform one-hot encoding on categorical features and create a DataFrame for the encoded features\n",
        "X_encoded = pd.DataFrame(encoder.fit_transform(X.select_dtypes(include='object')))\n",
        "X_encoded.columns = encoder.get_feature_names_out(X.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features\n",
        "X = pd.concat([X.select_dtypes(include=['float64', 'int64']), X_encoded], axis=1)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Display the shapes of the training, validation, and test sets\n",
        "print('Training set shape:', X_train.shape, y_train.shape)\n",
        "print('Validation set shape:', X_val.shape, y_val.shape)\n",
        "print('Test set shape:', X_test.shape, y_test.shape)\n",
        "\n",
        "# Import the Support Vector Classifier model and accuracy metric\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize a Support Vector Classifier model\n",
        "model = SVC()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate training accuracy\n",
        "train_predictions = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "# Make predictions on the validation set and calculate validation accuracy\n",
        "val_predictions = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "# Make predictions on the test set and calculate test accuracy\n",
        "test_predictions = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Display the training, validation, and test accuracies\n",
        "print('Training Accuracy:', train_accuracy*100,\"%\")\n",
        "print('Validation Accuracy:', val_accuracy*100,\"%\")\n",
        "print('Test Accuracy:', test_accuracy*100,\"%\")\n",
        "\n",
        "precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Display precision, recall, and F1 score for the test set\n",
        "print(' Precision is :', precision)\n",
        "print(' Recall is :', recall)\n",
        "print(' F1 Score is :', f1)\n",
        "\n",
        "# Install joblib\n",
        "!pip install joblib\n",
        "\n",
        "# Import joblib for model saving\n",
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(model, 'saved_model.pkl')\n",
        "\n",
        "# Load the saved model from the file\n",
        "loaded_model = joblib.load('saved_model.pkl')\n",
        "\n",
        "# Read new data from 'dataTEST.csv'  # for testing\n",
        "new_data = pd.read_csv('dataTEST.csv')\n",
        "\n",
        "# Perform one-hot encoding on the new data\n",
        "new_data_encoded = pd.DataFrame(encoder.transform(new_data.select_dtypes(include='object')))\n",
        "new_data_encoded.columns = encoder.get_feature_names_out(new_data.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features in the new data\n",
        "new_data = pd.concat([new_data.select_dtypes(include=['float64', 'int64']), new_data_encoded], axis=1)\n",
        "\n",
        "# Make predictions on the new data using the loaded model\n",
        "predictions = loaded_model.predict(new_data)\n",
        "\n",
        "# Display the predictions\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the dataset from a CSV file into a pandas DataFrame\n",
        "data = pd.read_csv('dataSET-1.csv')\n",
        "\n",
        "# Define the features and target variable\n",
        "features = ['weather', 'transportation', 'start', 'traffic', 'duration', 'previous tardiness']\n",
        "target = 'tardiness'\n",
        "\n",
        "# Extract features (X) and target variable (y) from the dataset\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Initialize a OneHotEncoder to handle categorical variables\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# Perform one-hot encoding on categorical features and create a DataFrame for the encoded features\n",
        "X_encoded = pd.DataFrame(encoder.fit_transform(X.select_dtypes(include='object')))\n",
        "X_encoded.columns = encoder.get_feature_names_out(X.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features\n",
        "X = pd.concat([X.select_dtypes(include=['float64', 'int64']), X_encoded], axis=1)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Display the shapes of the training, validation, and test sets\n",
        "print('Training set shape:', X_train.shape, y_train.shape)\n",
        "print('Validation set shape:', X_val.shape, y_val.shape)\n",
        "print('Test set shape:', X_test.shape, y_test.shape)\n",
        "\n",
        "# Import the Decision Tree Classifier and accuracy metric\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize a Decision Tree Classifier model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate training accuracy\n",
        "train_predictions = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "# Make predictions on the validation set and calculate validation accuracy\n",
        "val_predictions = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "# Make predictions on the test set and calculate test accuracy\n",
        "test_predictions = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Display the training, validation, and test accuracies\n",
        "print('Training Accuracy:', train_accuracy)\n",
        "print('Validation Accuracy:', val_accuracy)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "\n",
        "precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Display precision, recall, and F1 score for the test set\n",
        "print(' Precision is :', precision)\n",
        "print(' Recall is :', recall)\n",
        "print(' F1 Score is :', f1)\n",
        "\n",
        "# Install joblib\n",
        "!pip install joblib\n",
        "\n",
        "# Import joblib for model saving\n",
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(model, 'saved_model.pkl')\n",
        "\n",
        "# Load the saved model from the file\n",
        "loaded_model = joblib.load('saved_model.pkl')\n",
        "\n",
        "# Read new data from 'dataTEST.csv'  # for testing\n",
        "new_data = pd.read_csv('dataTEST.csv')\n",
        "\n",
        "# Perform one-hot encoding on the new data\n",
        "new_data_encoded = pd.DataFrame(encoder.transform(new_data.select_dtypes(include='object')))\n",
        "new_data_encoded.columns = encoder.get_feature_names_out(new_data.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features in the new data\n",
        "new_data = pd.concat([new_data.select_dtypes(include=['float64', 'int64']), new_data_encoded], axis=1)\n",
        "\n",
        "# Make predictions on the new data using the loaded model\n",
        "predictions = loaded_model.predict(new_data)\n",
        "\n",
        "# Display the predictions\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLQEImrSeUT_",
        "outputId": "75b4e90d-62d8-418f-e71e-2e2f06f6ea6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (6999, 11) (6999,)\n",
            "Validation set shape: (1500, 11) (1500,)\n",
            "Test set shape: (1500, 11) (1500,)\n",
            "Training Accuracy: 1.0\n",
            "Validation Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            " Precision is : 1.0\n",
            " Recall is : 1.0\n",
            " F1 Score is : 1.0\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the dataset from a CSV file into a pandas DataFrame\n",
        "data = pd.read_csv('dataSET-1.csv')\n",
        "\n",
        "# Define the features and target variable\n",
        "features = ['weather', 'transportation', 'start', 'traffic', 'duration', 'previous tardiness']\n",
        "target = 'tardiness'\n",
        "\n",
        "# Extract features (X) and target variable (y) from the dataset\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Initialize a OneHotEncoder to handle categorical variables\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# Perform one-hot encoding on categorical features and create a DataFrame for the encoded features\n",
        "X_encoded = pd.DataFrame(encoder.fit_transform(X.select_dtypes(include='object')))\n",
        "X_encoded.columns = encoder.get_feature_names_out(X.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features\n",
        "X = pd.concat([X.select_dtypes(include=['float64', 'int64']), X_encoded], axis=1)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Display the shapes of the training, validation, and test sets\n",
        "print('Training set shape:', X_train.shape, y_train.shape)\n",
        "print('Validation set shape:', X_val.shape, y_val.shape)\n",
        "print('Test set shape:', X_test.shape, y_test.shape)\n",
        "\n",
        "# Import the Gaussian Naive Bayes model and accuracy metric\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize a Gaussian Naive Bayes model\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate training accuracy\n",
        "train_predictions = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "# Make predictions on the validation set and calculate validation accuracy\n",
        "val_predictions = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "# Make predictions on the test set and calculate test accuracy\n",
        "test_predictions = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Display the training, validation, and test accuracies\n",
        "print('Training Accuracy:', train_accuracy)\n",
        "print('Validation Accuracy:', val_accuracy)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "\n",
        "precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Display precision, recall, and F1 score for the test set\n",
        "print(' Precision is :', precision)\n",
        "print(' Recall is :', recall)\n",
        "print(' F1 Score is :', f1)\n",
        "\n",
        "# Install joblib\n",
        "!pip install joblib\n",
        "\n",
        "# Import joblib for model saving\n",
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(model, 'saved_model.pkl')\n",
        "\n",
        "# Load the saved model from the file\n",
        "loaded_model = joblib.load('saved_model.pkl')\n",
        "\n",
        "# Read new data from 'dataTEST.csv'  # for testing\n",
        "new_data = pd.read_csv('dataTEST.csv')\n",
        "\n",
        "# Perform one-hot encoding on the new data\n",
        "new_data_encoded = pd.DataFrame(encoder.transform(new_data.select_dtypes(include='object')))\n",
        "new_data_encoded.columns = encoder.get_feature_names_out(new_data.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features in the new data\n",
        "new_data = pd.concat([new_data.select_dtypes(include=['float64', 'int64']), new_data_encoded], axis=1)\n",
        "\n",
        "# Make predictions on the new data using the loaded model\n",
        "predictions = loaded_model.predict(new_data)\n",
        "\n",
        "# Display the predictions\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXt3r4P2eUcv",
        "outputId": "3d310c78-d7e0-417b-e65d-813700dac7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (6999, 11) (6999,)\n",
            "Validation set shape: (1500, 11) (1500,)\n",
            "Test set shape: (1500, 11) (1500,)\n",
            "Training Accuracy: 0.9878554079154165\n",
            "Validation Accuracy: 0.988\n",
            "Test Accuracy: 0.9893333333333333\n",
            " Precision is : 0.9896823449216087\n",
            " Recall is : 0.9893333333333333\n",
            " F1 Score is : 0.9893801663065648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the dataset from a CSV file into a pandas DataFrame\n",
        "data = pd.read_csv('dataSET-1.csv')\n",
        "\n",
        "# Define the features and target variable\n",
        "features = ['weather', 'transportation', 'start', 'traffic', 'duration', 'previous tardiness']\n",
        "target = 'tardiness'\n",
        "\n",
        "# Extract features (X) and target variable (y) from the dataset\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Initialize a OneHotEncoder to handle categorical variables\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# Perform one-hot encoding on categorical features and create a DataFrame for the encoded features\n",
        "X_encoded = pd.DataFrame(encoder.fit_transform(X.select_dtypes(include='object')))\n",
        "X_encoded.columns = encoder.get_feature_names_out(X.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features\n",
        "X = pd.concat([X.select_dtypes(include=['float64', 'int64']), X_encoded], axis=1)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Display the shapes of the training, validation, and test sets\n",
        "print('Training set shape:', X_train.shape, y_train.shape)\n",
        "print('Validation set shape:', X_val.shape, y_val.shape)\n",
        "print('Test set shape:', X_test.shape, y_test.shape)\n",
        "\n",
        "# Import the K-Nearest Neighbors (KNN) model and accuracy metric\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize a K-Nearest Neighbors (KNN) model\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate training accuracy\n",
        "train_predictions = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "# Make predictions on the validation set and calculate validation accuracy\n",
        "val_predictions = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "# Make predictions on the test set and calculate test accuracy\n",
        "test_predictions = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Display the training, validation, and test accuracies\n",
        "print('Training Accuracy:', train_accuracy)\n",
        "print('Validation Accuracy:', val_accuracy)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "\n",
        "precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Display precision, recall, and F1 score for the test set\n",
        "print(' Precision is :', precision)\n",
        "print(' Recall is :', recall)\n",
        "print(' F1 Score is :', f1)\n",
        "\n",
        "# Install joblib\n",
        "!pip install joblib\n",
        "\n",
        "# Import joblib for model saving\n",
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(model, 'saved_model.pkl')\n",
        "\n",
        "# Load the saved model from the file\n",
        "loaded_model = joblib.load('saved_model.pkl')\n",
        "\n",
        "# Read new data from 'dataTEST.csv'  # for testing\n",
        "new_data = pd.read_csv('dataTEST.csv')\n",
        "\n",
        "# Perform one-hot encoding on the new data\n",
        "new_data_encoded = pd.DataFrame(encoder.transform(new_data.select_dtypes(include='object')))\n",
        "new_data_encoded.columns = encoder.get_feature_names_out(new_data.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features in the new data\n",
        "new_data = pd.concat([new_data.select_dtypes(include=['float64', 'int64']), new_data_encoded], axis=1)\n",
        "\n",
        "# Make predictions on the new data using the loaded model\n",
        "predictions = loaded_model.predict(new_data)\n",
        "\n",
        "# Display the predictions\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aClXOCV7eUg-",
        "outputId": "84363fb7-95c9-4fb6-c69d-57004f037ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (6999, 11) (6999,)\n",
            "Validation set shape: (1500, 11) (1500,)\n",
            "Test set shape: (1500, 11) (1500,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0\n",
            "Validation Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            " Precision is : 1.0\n",
            " Recall is : 1.0\n",
            " F1 Score is : 1.0\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the dataset from a CSV file into a pandas DataFrame\n",
        "data = pd.read_csv('dataSET-1.csv')\n",
        "\n",
        "# Define the features and target variable\n",
        "features = ['weather', 'transportation', 'start', 'traffic', 'duration', 'previous tardiness']\n",
        "target = 'tardiness'\n",
        "\n",
        "# Extract features (X) and target variable (y) from the dataset\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Initialize a OneHotEncoder to handle categorical variables\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "# Perform one-hot encoding on categorical features and create a DataFrame for the encoded features\n",
        "X_encoded = pd.DataFrame(encoder.fit_transform(X.select_dtypes(include='object')))\n",
        "X_encoded.columns = encoder.get_feature_names_out(X.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features\n",
        "X = pd.concat([X.select_dtypes(include=['float64', 'int64']), X_encoded], axis=1)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Display the shapes of the training, validation, and test sets\n",
        "print('Training set shape:', X_train.shape, y_train.shape)\n",
        "print('Validation set shape:', X_val.shape, y_val.shape)\n",
        "print('Test set shape:', X_test.shape, y_test.shape)\n",
        "\n",
        "# Import the Gradient Boosting Classifier and accuracy metric\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize a Gradient Boosting Classifier model\n",
        "model = GradientBoostingClassifier()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate training accuracy\n",
        "train_predictions = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "\n",
        "# Make predictions on the validation set and calculate validation accuracy\n",
        "val_predictions = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "# Make predictions on the test set and calculate test accuracy\n",
        "test_predictions = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "# Display the training, validation, and test accuracies\n",
        "print('Training Accuracy:', train_accuracy)\n",
        "print('Validation Accuracy:', val_accuracy)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "\n",
        "precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Display precision, recall, and F1 score for the test set\n",
        "print(' Precision is :', precision)\n",
        "print(' Recall is :', recall)\n",
        "print(' F1 Score is :', f1)\n",
        "\n",
        "# Install joblib\n",
        "!pip install joblib\n",
        "\n",
        "# Import joblib for model saving\n",
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(model, 'saved_model.pkl')\n",
        "\n",
        "# Load the saved model from the file\n",
        "loaded_model = joblib.load('saved_model.pkl')\n",
        "\n",
        "# Read new data from 'dataTEST.csv'  # for testing\n",
        "new_data = pd.read_csv('dataTEST.csv')\n",
        "\n",
        "# Perform one-hot encoding on the new data\n",
        "new_data_encoded = pd.DataFrame(encoder.transform(new_data.select_dtypes(include='object')))\n",
        "new_data_encoded.columns = encoder.get_feature_names_out(new_data.select_dtypes(include='object').columns)\n",
        "\n",
        "# Concatenate the encoded features with the original numerical features in the new data\n",
        "new_data = pd.concat([new_data.select_dtypes(include=['float64', 'int64']), new_data_encoded], axis=1)\n",
        "\n",
        "# Make predictions on the new data using the loaded model\n",
        "predictions = loaded_model.predict(new_data)\n",
        "\n",
        "# Display the predictions\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdwsMK1qeUj2",
        "outputId": "0e3f27a6-54d3-430b-d4ab-700563e753ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (6999, 11) (6999,)\n",
            "Validation set shape: (1500, 11) (1500,)\n",
            "Test set shape: (1500, 11) (1500,)\n",
            "Training Accuracy: 1.0\n",
            "Validation Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            " Precision is : 1.0\n",
            " Recall is : 1.0\n",
            " F1 Score is : 1.0\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eeJHPdBaeUnh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}